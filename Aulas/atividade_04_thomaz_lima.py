# -*- coding: utf-8 -*-
"""Atividade_04_Thomaz_Lima.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jRVIOtsvD5ABy6qDqPPUN11KXtc4_feP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_wine
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, adjusted_rand_score
from IPython.display import display

sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 100
plt.rcParams['figure.figsize'] = (10, 6)

data = load_wine()
X = data.data
y_true = data.target
feature_names = data.feature_names

df = pd.DataFrame(X, columns=feature_names)
df['target'] = y_true
print(f"Dataset carregado: {df.shape[0]} amostras e {df.shape[1]-1} atributos.")
print(f"Número de rótulos: {len(np.unique(y_true))}")

# Padronização (StandardScaler)
# Justificativa: O K-Means é um algoritmo baseado em distância Euclidiana para medir a similaridade entre os pontos.

# Variáveis com escalas maiores (ex: 'magnesium', na casa das centenas) tendem a dominar
# o cálculo da distância total em comparação com variáveis de escalas menores (ex: 'alcohol', na casa de 12-14).
# Isso faria com que o agrupamento fosse tendencioso, refletindo a escala arbitrária das unidades
# de medida, em vez da importância estatística real dos atributos.
# O StandardScaler resolve isso, transformando os dados para que todos os atributos
# tenham **média zero** (μ=0) e **desvio padrão um** (σ=1).

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

desc_before = pd.DataFrame(X, columns=feature_names).describe().T[['mean','std']].rename(columns={'mean':'Média Original','std':'Desv. Padrão Original'})
desc_after = pd.DataFrame(X_scaled, columns=feature_names).describe().T[['mean','std']].rename(columns={'mean':'Média Padronizada','std':'Desv. Padrão Padronizado'})
desc_stats = pd.concat([desc_before, desc_after], axis=1).round(2)

print("\nEfeito do StandardScaler (valores ideais: Média=0, Desv. Padrão=1):")
display(desc_stats.head())

K_range = list(range(1,11))
wcss = []
sil_scores = {}

k_elbow = 3

for k in K_range:
    kmeans = KMeans(n_clusters=k, n_init=20, random_state=42)
    kmeans.fit(X_scaled)
    wcss.append(kmeans.inertia_)

    if k > 1:
        labels = kmeans.predict(X_scaled)
        sil = silhouette_score(X_scaled, labels)
        sil_scores[k] = sil

plt.figure(figsize=(8, 5))
plt.plot(K_range, wcss, marker='o', linestyle='-', color='#C24C38', linewidth=2, markersize=8)
plt.xlabel('Número de Clusters (k)', fontsize=12)
plt.ylabel('WCSS (Inércia)', fontsize=12)
plt.title('Método do Cotovelo - WCSS vs k', fontsize=14, fontweight='bold')
plt.xticks(K_range, fontsize=10)

wcss_at_elbow = wcss[k_elbow - 1]

plt.vlines(k_elbow, wcss[-1], wcss_at_elbow, linestyles='--', color='gray', alpha=0.7)

plt.annotate(f'Cotovelo (k={k_elbow})',
             xy=(k_elbow, wcss_at_elbow),
             xytext=(k_elbow + 0.5, wcss_at_elbow - 50),
             arrowprops=dict(facecolor='black', shrink=0.05, width=1, headwidth=8),
             fontsize=10, fontweight='bold')

plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

"""Ao analisarmos o gráfico, o mesmo apresenta um declínio acentuado da WCSS ao passar de 1 para 2 e dele para 3, o que mostra que a adição do segundo e do terceiro cluster realmente trouxe ganhos na compactação dos grupos. A partir desse ponto, a curva se torna muito mais suave, chegando a ser quase linear, de modo que a redução obtida ao avançar de 3 para 4, e sucessivamente, foi bem menor em comparação com as quedas anteriores. Assim, k=3 representa o melhor equilíbrio entre a compactação dos clusters e a complexidade do modelo, já que incluir mais clusters além disso não compensa, dado que os ganhos passam a ser mínimos."""

plt.figure(figsize=(8, 5))
ks = list(sil_scores.keys())
vals = list(sil_scores.values())
sns.lineplot(x=ks, y=vals, marker='o', color='#724C9F', linewidth=2, markersize=8)
plt.xlabel('Número de Clusters (k)', fontsize=12)
plt.ylabel('Silhouette Score Médio', fontsize=12)
plt.title('Avaliação por Silhouette Score', fontsize=14, fontweight='bold')
plt.xticks(ks, fontsize=10)

best_k_sil = max(sil_scores, key=sil_scores.get)
plt.vlines(best_k_sil, min(vals), max(vals), linestyles=':', color='green', alpha=0.8)
plt.annotate(f'Melhor k={best_k_sil}', xy=(best_k_sil, sil_scores[best_k_sil]), xytext=(best_k_sil + 0.5, sil_scores[best_k_sil] - 0.02),
             color='green', fontweight='bold')

plt.grid(axis='y', linestyle='--', alpha=0.6)
plt.tight_layout()
plt.show()

print(f"O Método do Cotovelo sugere k={best_k_sil}, que é o ponto onde o WCSS para de diminuir drasticamente.")
print(f"O Silhouette Score é maximizado em k={best_k_sil}.")
print(f"Como o número de classes reais no dataset Wine é {best_k_sil}, usaremos k={best_k_sil} para a análise final.")

chosen_k = 3

kmeans_final = KMeans(n_clusters=chosen_k, n_init=50, random_state=42)
labels_final = kmeans_final.fit_predict(X_scaled)

sil_final = silhouette_score(X_scaled, labels_final)
ari_final = adjusted_rand_score(y_true, labels_final)

print(f"\nK-Means ajustado com k={chosen_k}:")
print(f"Silhouette Score Médio = {sil_final:.4f}")
print(f"Adjusted Rand Index = {ari_final:.4f}")

cluster_counts = pd.Series(labels_final).value_counts().sort_index()
print("\nContagem de amostras por cluster:")
print(cluster_counts.to_string())

print("\nCrosstab: Cluster vs. Target:")
crosstab_df = pd.crosstab(index=y_true, columns=labels_final, rownames=['Target'], colnames=['Cluster K-Means'])
display(crosstab_df)

print(f"O ARI de {ari_final:.4f} indica uma alta concordância entre o agrupamento não supervisionado e as classes verdadeiras do vinho. O K-Means conseguiu separar bem as classes com base nos atributos químicos.")

"""O valor de 0.2849 para o Silhouette Score é positivo, mas relativamente baixo, o que indica um agrupamento foi moderado. Os clusters apresentam maior coerência interna do que incoerência, mas a separação entre eles ficou relativamente limitada, já que muitos pontos se encontram próximos das fronteiras que os dividem. Entretanto, o ARI de 0.8975 mostrou uma similaridade quase perfeita entre os clusters encontrados pelo K-Means e as classes reais do conjunto de vinhos, o que só mostra que, mesmo com a penalização na métrica de separação espacial, o algoritmo conseguiu se aproximar muito do que observamos no mundo real. Em síntese, o K-Means classificou corretamente a maioria das amostras, mas a proximidade natural entre as classes no espaço padronizado reduziu a nitidez da separação medida pelo Silhouette Score."""